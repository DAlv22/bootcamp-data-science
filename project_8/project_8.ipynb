{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROYECTO BETA BANK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El presente proyecto tiene por objetivo presentar un modelo que pueda ayudar a Beta Bank a predecir si un cliente dejará el banco pronto. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Inicialización\n",
    "\n",
    "El banco proporciona los datos sobre el comportamiento pasado de los clientes y la terminación de contratos con el banco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de librerias y de datos\n",
    "Ser carga la información proporcionada por Beta Bank sobre el comportamiento de sus clientes que han terminado relación con el banco.\n",
    "\n",
    "    - Para comenzar descargaremos las librerías necesarias para el tratamiento necesarios de los datos\n",
    "    - Posteriormente se revisarán las características generales de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza la importación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a la revisión de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 14)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "\n",
      "RowNumber            int64\n",
      "CustomerId           int64\n",
      "Surname             object\n",
      "CreditScore          int64\n",
      "Geography           object\n",
      "Gender              object\n",
      "Age                  int64\n",
      "Tenure             float64\n",
      "Balance            float64\n",
      "NumOfProducts        int64\n",
      "HasCrCard            int64\n",
      "IsActiveMember       int64\n",
      "EstimatedSalary    float64\n",
      "Exited               int64\n",
      "dtype: object\n",
      "\n",
      "         RowNumber    CustomerId   CreditScore           Age       Tenure  \\\n",
      "count  10000.00000  1.000000e+04  10000.000000  10000.000000  9091.000000   \n",
      "mean    5000.50000  1.569094e+07    650.528800     38.921800     4.997690   \n",
      "std     2886.89568  7.193619e+04     96.653299     10.487806     2.894723   \n",
      "min        1.00000  1.556570e+07    350.000000     18.000000     0.000000   \n",
      "25%     2500.75000  1.562853e+07    584.000000     32.000000     2.000000   \n",
      "50%     5000.50000  1.569074e+07    652.000000     37.000000     5.000000   \n",
      "75%     7500.25000  1.575323e+07    718.000000     44.000000     7.000000   \n",
      "max    10000.00000  1.581569e+07    850.000000     92.000000    10.000000   \n",
      "\n",
      "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
      "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
      "mean    76485.889288       1.530200      0.70550        0.515100   \n",
      "std     62397.405202       0.581654      0.45584        0.499797   \n",
      "min         0.000000       1.000000      0.00000        0.000000   \n",
      "25%         0.000000       1.000000      0.00000        0.000000   \n",
      "50%     97198.540000       1.000000      1.00000        1.000000   \n",
      "75%    127644.240000       2.000000      1.00000        1.000000   \n",
      "max    250898.090000       4.000000      1.00000        1.000000   \n",
      "\n",
      "       EstimatedSalary        Exited  \n",
      "count     10000.000000  10000.000000  \n",
      "mean     100090.239881      0.203700  \n",
      "std       57510.492818      0.402769  \n",
      "min          11.580000      0.000000  \n",
      "25%       51002.110000      0.000000  \n",
      "50%      100193.915000      0.000000  \n",
      "75%      149388.247500      0.000000  \n",
      "max      199992.480000      1.000000  \n",
      "\n",
      "Este dataset tiene 0 filas duplicadas.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10.0</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0        2.0       0.00              1          1               1   \n",
       "1        1.0   83807.86              1          0               1   \n",
       "2        8.0  159660.80              3          1               0   \n",
       "3        1.0       0.00              2          0               0   \n",
       "4        2.0  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995     5.0       0.00              2          1               0   \n",
       "9996    10.0   57369.61              1          1               1   \n",
       "9997     7.0       0.00              1          0               1   \n",
       "9998     3.0   75075.31              2          1               0   \n",
       "9999     NaN  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print()\n",
    "print(df.info())\n",
    "print()\n",
    "print(df.dtypes)\n",
    "print()\n",
    "print(df.describe())\n",
    "print()\n",
    "print(f'Este dataset tiene {df.duplicated().sum()} filas duplicadas.')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisión de los datos\n",
    "\n",
    "Tenemos un dataset con un tota del 10,000 filas y 14 columnas, de las cuales tenemos los siguientes encabezados y caracteristicas de los datos alojados en ellas:\n",
    "\n",
    "Nombre de columna | Descripción | Tipo de dato\n",
    "--- | --- | ---\n",
    "RowNumber | índice de cadena de dato | int64\n",
    "CustomerId | identificador de cliente único | int64\n",
    "Surname | apellido | object\n",
    "CreditScore | valor de crédito | int64\n",
    "Geography | país de residencia | object\n",
    "Gender | sexo | object\n",
    "Age | edad | int64\n",
    "Tenure | período durante el cual ha madurado el depósito a plazo fijo de un cliente (años) | float64\n",
    "Balance | saldo de la cuenta | float64\n",
    "NumOfProducts | número de productos bancarios utilizados por el cliente | int64\n",
    "HasCrCard | el cliente tiene una tarjeta de crédito (1 - sí; 0 - no) | int64\n",
    "IsActiveMember | actividad del cliente (1 - sí; 0 - no) | int64\n",
    "EstimatedSalary | salario estimado | float64\n",
    "Exited | El cliente se ha ido (1 - sí; 0 - no) | int64\n",
    "\n",
    "Teniendo un total de:\n",
    "- Datos flotantes (3)\n",
    "- Datos integer (8)\n",
    "- Datos objeto (3)\n",
    "\n",
    "La columna donde tenemos 909 datos faltantes es en la columna \"Tenure\", representando un 9% del total de datos. Las características de los datos faltantes se revisará más adelante. \n",
    "\n",
    "Esta es una tabla que muestra las principales características de las columnas que contienen datos númericos (Se excluyen las columnas \"RowNumber\" y \"CustomerId\" debido a que no es relevantes para este análisis)\n",
    "\n",
    "|   |CreditScore | Age | Tenure | Balance | NumOfProducts | HasCrCard | IsActiveMember | EstimatedSalary | Exited |\n",
    "|---|-------------|-----|--------|---------|---------------|-----------|-----------------|------------------|--------|\n",
    "| count | 10000 | 10000 | 9091 | 10000 | 10000 | 10000 | 10000 | 100000 | 10000 |\n",
    "| mean  | 650.5288 | 38.9218 | 4.9976 | 76485.8892 | 1.5302 | 0.7055 | 0.5151 | 100090.2398 | 0.2037 |\n",
    "| std | 96.653299 | 10.487806 | 2.894723 | 62397.405202 | 0.581654 | 0.45584 | 0.499797 | 57510.492818 | 0.402769 |\n",
    "| min | 350 | 18 | 0 | 0 | 1 | 0 | 0 | 11.58 | 0 |\n",
    "| 25% | 584 | 32 | 2 | 0 | 1 | 0 | 0 | 51002.11 | 0 |\n",
    "| 50% | 652 | 37 | 5 | 97198.54 | 1 | 1 | 1 | 100193.915 | 0 |\n",
    "| 75% | 718 | 44 | 7 | 127644.24 | 2 | 1 | 1 | 149388.2475 | 0 |\n",
    "| max | 850 | 92 | 10 | 250898.09 | 4 | 1 | 1 | 199992.48 | 1 |\n",
    " \n",
    "Hay datos que son faciles de entender a la vista, pero nos centraremos en aquellas columnas cuyos datos son binarios.\n",
    "\n",
    "    - HasCrCard: cuya media indica que el 71% son clientes que tienen una tarjeta de crédito\n",
    "    - IsActiveMember: cuya media indica que el 52% son clientes están activos\n",
    "    - Exited: cuya media indica que el 20% indica que los clientes se han ido\n",
    "    \n",
    "    \n",
    "Este dataset tiene 0 filas duplicadas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escrutinio y ajuste de datos\n",
    "\n",
    "Una vez con una noción general de los datos con los cuales se trabaja, se procede a hacer un análisis y ajuste de los datos para poder comenzar a trabajar con ellos.\n",
    "\n",
    "Se comienza ajustando los encabezados de columna a minúsculas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   row_number  customer_id   surname  credit_score geography  gender  age  \\\n",
      "0           1     15634602  Hargrave           619    France  Female   42   \n",
      "1           2     15647311      Hill           608     Spain  Female   41   \n",
      "2           3     15619304      Onio           502    France  Female   42   \n",
      "3           4     15701354      Boni           699    France  Female   39   \n",
      "4           5     15737888  Mitchell           850     Spain  Female   43   \n",
      "\n",
      "   tenure    balance  num_of_products  has_crcard  is_active_member  \\\n",
      "0     2.0       0.00                1           1                 1   \n",
      "1     1.0   83807.86                1           0                 1   \n",
      "2     8.0  159660.80                3           1                 0   \n",
      "3     1.0       0.00                2           0                 0   \n",
      "4     2.0  125510.82                1           1                 1   \n",
      "\n",
      "   estimated_salary  exited  \n",
      "0         101348.88       1  \n",
      "1         112542.58       0  \n",
      "2         113931.57       1  \n",
      "3          93826.63       0  \n",
      "4          79084.10       0  \n"
     ]
    }
   ],
   "source": [
    "df.columns = df.columns.str.lower()\n",
    "df = df.rename(columns={\n",
    "    'hascrcard': 'has_cr_card',\n",
    "    'rownumber': 'row_number',\n",
    "    'customerid': 'customer_id',\n",
    "    'creditscore': 'credit_score',\n",
    "    'numofproducts': 'num_of_products',\n",
    "    'hascrcard': 'has_crcard',\n",
    "    'isactivemember': 'is_active_member',\n",
    "    'estimatedsalary': 'estimated_salary'})\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a revisar los datos nulos ubicados en la columna 'tenure'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  1.  8.  7.  4.  6.  3. 10.  5.  9.  0. nan]\n"
     ]
    }
   ],
   "source": [
    "print(df['tenure'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que dentro de los datos unicos que hay en 'tenure'va acorde a nuesta tabla anterior, cuyo mínimo es 0 y máximo es 10. Esto cancela la idea de que los datos 'nan' de esta columna, pudieran ser los clientes que aún no cumplian un año con el banco, dado que sí hay clientes que tienen marcado el año '0'.\n",
    "\n",
    "Se filtra el dataset por los datos nulos de 'tenure' para revisar si existe alguna tendencia que podamos ver a simple vista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_number</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>surname</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>geography</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>num_of_products</th>\n",
       "      <th>has_crcard</th>\n",
       "      <th>is_active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>15589475</td>\n",
       "      <td>Azikiwe</td>\n",
       "      <td>591</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140469.38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>15766205</td>\n",
       "      <td>Yin</td>\n",
       "      <td>550</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103391.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90878.13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>15768193</td>\n",
       "      <td>Trevisani</td>\n",
       "      <td>585</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146050.97</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86424.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>15702298</td>\n",
       "      <td>Parkhill</td>\n",
       "      <td>655</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125561.97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164040.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>15651280</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>742</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136857.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84509.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9944</th>\n",
       "      <td>9945</td>\n",
       "      <td>15703923</td>\n",
       "      <td>Cameron</td>\n",
       "      <td>744</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190409.34</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>138361.48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9956</th>\n",
       "      <td>9957</td>\n",
       "      <td>15707861</td>\n",
       "      <td>Nucci</td>\n",
       "      <td>520</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85216.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>117369.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9964</th>\n",
       "      <td>9965</td>\n",
       "      <td>15642785</td>\n",
       "      <td>Douglas</td>\n",
       "      <td>479</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117593.48</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113308.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>9986</td>\n",
       "      <td>15586914</td>\n",
       "      <td>Nepean</td>\n",
       "      <td>659</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123841.49</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96833.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>909 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_number  customer_id    surname  credit_score geography  gender  age  \\\n",
       "30            31     15589475    Azikiwe           591     Spain  Female   39   \n",
       "48            49     15766205        Yin           550   Germany    Male   38   \n",
       "51            52     15768193  Trevisani           585   Germany    Male   36   \n",
       "53            54     15702298   Parkhill           655   Germany    Male   41   \n",
       "60            61     15651280     Hunter           742   Germany    Male   35   \n",
       "...          ...          ...        ...           ...       ...     ...  ...   \n",
       "9944        9945     15703923    Cameron           744   Germany    Male   41   \n",
       "9956        9957     15707861      Nucci           520    France  Female   46   \n",
       "9964        9965     15642785    Douglas           479    France    Male   34   \n",
       "9985        9986     15586914     Nepean           659    France    Male   36   \n",
       "9999       10000     15628319     Walker           792    France  Female   28   \n",
       "\n",
       "      tenure    balance  num_of_products  has_crcard  is_active_member  \\\n",
       "30       NaN       0.00                3           1                 0   \n",
       "48       NaN  103391.38                1           0                 1   \n",
       "51       NaN  146050.97                2           0                 0   \n",
       "53       NaN  125561.97                1           0                 0   \n",
       "60       NaN  136857.00                1           0                 0   \n",
       "...      ...        ...              ...         ...               ...   \n",
       "9944     NaN  190409.34                2           1                 1   \n",
       "9956     NaN   85216.61                1           1                 0   \n",
       "9964     NaN  117593.48                2           0                 0   \n",
       "9985     NaN  123841.49                2           1                 0   \n",
       "9999     NaN  130142.79                1           1                 0   \n",
       "\n",
       "      estimated_salary  exited  \n",
       "30           140469.38       1  \n",
       "48            90878.13       0  \n",
       "51            86424.57       0  \n",
       "53           164040.94       1  \n",
       "60            84509.57       0  \n",
       "...                ...     ...  \n",
       "9944         138361.48       0  \n",
       "9956         117369.52       1  \n",
       "9964         113308.29       0  \n",
       "9985          96833.00       0  \n",
       "9999          38190.78       0  \n",
       "\n",
       "[909 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filtered_df = df[df['tenure'].isna()]\n",
    "display(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece no haber una tendencia por la cual tengamos datos 'NaN' en la columna de 'tenure'.\n",
    "Por ultimo se realizará una revisón por 'geography' para ver si existe algún tipo de tendencia en los datos 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Spain' 'Germany' 'France']\n"
     ]
    }
   ],
   "source": [
    "print(filtered_df['geography'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      row_number  customer_id    surname  credit_score geography  gender  age  \\\n",
      "48            49     15766205        Yin           550   Germany    Male   38   \n",
      "51            52     15768193  Trevisani           585   Germany    Male   36   \n",
      "53            54     15702298   Parkhill           655   Germany    Male   41   \n",
      "60            61     15651280     Hunter           742   Germany    Male   35   \n",
      "111          112     15665790   Rowntree           538   Germany    Male   39   \n",
      "...          ...          ...        ...           ...       ...     ...  ...   \n",
      "9822        9823     15781298     Hughes           808   Germany    Male   39   \n",
      "9858        9859     15619514       Bull           507   Germany    Male   40   \n",
      "9864        9865     15652999      Milne           742   Germany    Male   33   \n",
      "9901        9902     15802909         Hu           706   Germany  Female   56   \n",
      "9944        9945     15703923    Cameron           744   Germany    Male   41   \n",
      "\n",
      "      tenure    balance  num_of_products  has_crcard  is_active_member  \\\n",
      "48       NaN  103391.38                1           0                 1   \n",
      "51       NaN  146050.97                2           0                 0   \n",
      "53       NaN  125561.97                1           0                 0   \n",
      "60       NaN  136857.00                1           0                 0   \n",
      "111      NaN  108055.10                2           1                 0   \n",
      "...      ...        ...              ...         ...               ...   \n",
      "9822     NaN  124216.93                1           0                 1   \n",
      "9858     NaN  120105.43                1           1                 0   \n",
      "9864     NaN  137937.95                1           1                 1   \n",
      "9901     NaN  139603.22                1           1                 1   \n",
      "9944     NaN  190409.34                2           1                 1   \n",
      "\n",
      "      estimated_salary  exited  \n",
      "48            90878.13       0  \n",
      "51            86424.57       0  \n",
      "53           164040.94       1  \n",
      "60            84509.57       0  \n",
      "111           27231.26       0  \n",
      "...                ...     ...  \n",
      "9822         171442.36       0  \n",
      "9858          92075.01       1  \n",
      "9864          51387.10       0  \n",
      "9901          86383.61       0  \n",
      "9944         138361.48       0  \n",
      "\n",
      "[216 rows x 14 columns]\n",
      "      row_number  customer_id    surname  credit_score geography  gender  age  \\\n",
      "30            31     15589475    Azikiwe           591     Spain  Female   39   \n",
      "85            86     15805254    Ndukaku           652     Spain  Female   75   \n",
      "94            95     15676966      Capon           730     Spain    Male   42   \n",
      "146          147     15705707  Bennelong           635     Spain  Female   29   \n",
      "180          181     15716334     Rozier           850     Spain  Female   45   \n",
      "...          ...          ...        ...           ...       ...     ...  ...   \n",
      "9585        9586     15610557   McCarthy           695     Spain  Female   35   \n",
      "9846        9847     15596405    Udinese           546     Spain    Male   25   \n",
      "9853        9854     15576615   Giordano           719     Spain    Male   37   \n",
      "9889        9890     15711489    Azikiwe           760     Spain  Female   32   \n",
      "9938        9939     15593496    Korovin           526     Spain  Female   36   \n",
      "\n",
      "      tenure    balance  num_of_products  has_crcard  is_active_member  \\\n",
      "30       NaN       0.00                3           1                 0   \n",
      "85       NaN       0.00                2           1                 1   \n",
      "94       NaN       0.00                2           0                 1   \n",
      "146      NaN  138296.94                2           1                 0   \n",
      "180      NaN  122311.21                1           1                 1   \n",
      "...      ...        ...              ...         ...               ...   \n",
      "9585     NaN   79858.13                2           1                 1   \n",
      "9846     NaN  127728.24                2           1                 1   \n",
      "9853     NaN  145382.61                1           1                 0   \n",
      "9889     NaN       0.00                1           1                 1   \n",
      "9938     NaN   91132.18                1           0                 0   \n",
      "\n",
      "      estimated_salary  exited  \n",
      "30           140469.38       1  \n",
      "85           114675.75       0  \n",
      "94            85982.47       0  \n",
      "146          141075.51       0  \n",
      "180           19482.50       0  \n",
      "...                ...     ...  \n",
      "9585         127977.66       0  \n",
      "9846         105279.74       0  \n",
      "9853          80408.59       0  \n",
      "9889         114565.35       0  \n",
      "9938          58111.71       0  \n",
      "\n",
      "[229 rows x 14 columns]\n",
      "      row_number  customer_id  surname  credit_score geography  gender  age  \\\n",
      "82            83     15641732    Mills           543    France  Female   36   \n",
      "99           100     15633059  Fanucci           413    France    Male   34   \n",
      "125          126     15627360   Fuller           432    France    Male   42   \n",
      "162          163     15630910   Treacy           800    France  Female   49   \n",
      "173          174     15586310     Ting           578    France    Male   30   \n",
      "...          ...          ...      ...           ...       ...     ...  ...   \n",
      "9931        9932     15647800    Greco           850    France  Female   34   \n",
      "9956        9957     15707861    Nucci           520    France  Female   46   \n",
      "9964        9965     15642785  Douglas           479    France    Male   34   \n",
      "9985        9986     15586914   Nepean           659    France    Male   36   \n",
      "9999       10000     15628319   Walker           792    France  Female   28   \n",
      "\n",
      "      tenure    balance  num_of_products  has_crcard  is_active_member  \\\n",
      "82       NaN       0.00                2           0                 0   \n",
      "99       NaN       0.00                2           0                 0   \n",
      "125      NaN  152603.45                1           1                 0   \n",
      "162      NaN  108007.36                1           0                 0   \n",
      "173      NaN  169462.09                1           1                 0   \n",
      "...      ...        ...              ...         ...               ...   \n",
      "9931     NaN  101266.51                1           1                 0   \n",
      "9956     NaN   85216.61                1           1                 0   \n",
      "9964     NaN  117593.48                2           0                 0   \n",
      "9985     NaN  123841.49                2           1                 0   \n",
      "9999     NaN  130142.79                1           1                 0   \n",
      "\n",
      "      estimated_salary  exited  \n",
      "82            26019.59       0  \n",
      "99             6534.18       0  \n",
      "125          110265.24       1  \n",
      "162           47125.11       0  \n",
      "173          112187.11       0  \n",
      "...                ...     ...  \n",
      "9931          33501.98       0  \n",
      "9956         117369.52       1  \n",
      "9964         113308.29       0  \n",
      "9985          96833.00       0  \n",
      "9999          38190.78       0  \n",
      "\n",
      "[464 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "germany_data = filtered_df[filtered_df['geography'] == 'Germany']\n",
    "print(germany_data)\n",
    "spain_data = filtered_df[filtered_df['geography'] == 'Spain']\n",
    "print(spain_data)\n",
    "france_data = filtered_df[filtered_df['geography'] == 'France']\n",
    "print(france_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece no haber una tendencia por la cual tengamos datos 'NaN' en la columna de 'tenure'.\n",
    "\n",
    "Se toma la desición de eliminar las filas que contengan NaN, debido a que no tenemos claro el porqué estos datos están ausentes y por temas de ejercicio. Se considera que lo más adecuado sería poder consultar al banco, el porqué de los datos ausentes.\n",
    "\n",
    "Se eliminará con esto el 9% de los datos del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9091, 14)\n"
     ]
    }
   ],
   "source": [
    "df_clean = df.dropna(subset=['tenure'])\n",
    "print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a realizar el último tratamiento a los datos que será:\n",
    "\n",
    "    - Eliminar las columnas que no son relevantes para nuestro modelo \n",
    "        - RowNumber: índice de cadena de dato\n",
    "        - CustomerId: identificador de cliente único\n",
    "        - Surname: apellido\t\n",
    "\n",
    "Estas columnas parecen ser identificadores únicos o índices y no aportarán información significativa al modelo.\n",
    "\n",
    "Se codificarán las columnas:\n",
    "\n",
    "    - Geography\n",
    "    - Gender\n",
    "\n",
    "Puesto que estas columnas son categóricas y se necesitará codificarlas para que el modelo pueda trabajar con ellas. Se decide trabajar con OrdinalEncoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   credit_score  geography  gender   age  tenure  balance  num_of_products  \\\n",
      "0         226.0        0.0     0.0  24.0     2.0      0.0              0.0   \n",
      "1         215.0        2.0     0.0  23.0     1.0    679.0              0.0   \n",
      "2         109.0        0.0     0.0  24.0     8.0   5277.0              2.0   \n",
      "3         306.0        0.0     0.0  21.0     1.0      0.0              1.0   \n",
      "4         457.0        2.0     0.0  25.0     2.0   3374.0              0.0   \n",
      "5         252.0        2.0     1.0  26.0     8.0   2435.0              1.0   \n",
      "6         429.0        0.0     1.0  32.0     7.0      0.0              1.0   \n",
      "7           7.0        1.0     0.0  11.0     4.0   2536.0              3.0   \n",
      "8         108.0        0.0     1.0  26.0     4.0   4511.0              1.0   \n",
      "9         291.0        0.0     1.0   9.0     2.0   4061.0              0.0   \n",
      "\n",
      "   has_crcard  is_active_member  estimated_salary  exited  \n",
      "0         1.0               1.0            4609.0     1.0  \n",
      "1         0.0               1.0            5119.0     0.0  \n",
      "2         1.0               0.0            5182.0     1.0  \n",
      "3         0.0               0.0            4274.0     0.0  \n",
      "4         1.0               1.0            3559.0     0.0  \n",
      "5         1.0               0.0            6833.0     1.0  \n",
      "6         1.0               1.0             473.0     0.0  \n",
      "7         1.0               0.0            5426.0     1.0  \n",
      "8         0.0               1.0            3372.0     0.0  \n",
      "9         1.0               1.0            3216.0     0.0  \n"
     ]
    }
   ],
   "source": [
    "data = df_clean.drop(['row_number', 'customer_id', 'surname'], axis=1)\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "data_ordinal = pd.DataFrame(encoder.fit_transform(data), columns=data.columns)\n",
    "print(data_ordinal.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de modelo sin equilibrio\n",
    "\n",
    "Con el escrutinio de los datos, se sabe que hay un desequilibrio de clases. \n",
    "A modo de recordatorio:\n",
    "\n",
    "    - Exited: cuya media indica que el 20% indica que los clientes se han ido\n",
    "    \n",
    "Se procede a entrenar el modelo sin estar equilibrado para ver qué resultados arroja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentación de los datos\n",
    "\n",
    "Se procede a la segmentación de los datos para poder trabajar con ellos.\n",
    "Al tener un solo dataset y no contar con un dataset de prueba a futuro, se dividirá el total del dataset de la siguiente manera:\n",
    "- 60% dataset de entrenamiento\n",
    "- 20% dataset de validación\n",
    "- 20% Dataset de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_ordinal.drop(['exited'], axis=1)\n",
    "target = data_ordinal['exited']\n",
    "\n",
    "features_train, x_train, target_train, y_valid = train_test_split(features, target, test_size=0.40, random_state=12345)\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(x_train, y_valid, test_size=0.50, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos\n",
    "\n",
    "Ya segmentados los datos se entrenan 3 modelos para encontrar el modelo y los hiperparámetros que arrojen los mejores resultados:\n",
    "\n",
    "    - Árbol de decisión\n",
    "    - Bosque aleatorio\n",
    "    - Regresión logística\n",
    "    \n",
    "Se utilizará 'F1 score' y 'AUC ROC' como métricas generales para entender la calidad del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Árbol de desición\n",
    "\n",
    "Se elabora árbol de decisión, ejecutando dentro del modelo, un verificador que nos ayuda a saber los mejores hiperparámetros para el mismo modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Valor de f1 del mejor modelo sin balance en el conjunto de validacion es de: 0.5513698630136986\n",
      "Resultado alcanzado con una profundidad de 5\n",
      "El valor de AUC-ROC es de: 0.8349528860189559\n"
     ]
    }
   ],
   "source": [
    "best_model_tree_unbalanced = None\n",
    "best_result_tree_unbalanced = 0\n",
    "best_depth_tree_unbalanced = 0\n",
    "\n",
    "for depth in range(1, 6):\n",
    "    model_tree_unbalanced = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    train_tree_unbalanced = model_tree_unbalanced.fit(features_train, target_train)\n",
    "    predictions_tree_unbalanced = model_tree_unbalanced.predict(features_valid)\n",
    "    result_tree_unbalanced = f1_score(target_valid, predictions_tree_unbalanced)\n",
    "    \n",
    "    if result_tree_unbalanced > best_result_tree_unbalanced:\n",
    "        best_model_tree_unbalanced = model_tree_unbalanced\n",
    "        best_result_tree_unbalanced = result_tree_unbalanced\n",
    "        best_depth_tree_unbalanced = depth\n",
    "\n",
    "print(\"El Valor de f1 del mejor modelo sin balance en el conjunto de validacion es de:\", best_result_tree_unbalanced)\n",
    "print(\"Resultado alcanzado con una profundidad de\", best_depth_tree_unbalanced)\n",
    "\n",
    "\n",
    "probabilities_valid_tree_unbalanced = model_tree_unbalanced.predict_proba(features_valid)\n",
    "probabilities_one_valid_tree_unbalanced = probabilities_valid_tree_unbalanced[:, 1]\n",
    "auc_roc_tree_unbalanced = roc_auc_score(target_valid, probabilities_one_valid_tree_unbalanced)\n",
    "\n",
    "print(f'El valor de AUC-ROC es de: {auc_roc_tree_unbalanced}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bosque Aleatorio\n",
    "\n",
    "Se elabora un bosque aleatorio, ejecutando dentro del modelo, un verificador que nos ayuda a saber los mejores hiperparámetros para el mismo modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Valor de f1 del mejor modelo sin balance en el conjunto de validacion es de: 0.55\n",
      "Resultado alcanzado con una profundidad de 6\n",
      "El valor de AUC-ROC es de: 0.8664794010937733\n"
     ]
    }
   ],
   "source": [
    "best_model_forest_unbalanced= None\n",
    "best_result_forest_unbalanced= 0\n",
    "best_depth_forest_unbalanced = 0\n",
    "\n",
    "for depth in range(1,10):\n",
    "    model_forest_unbalanced = RandomForestClassifier(random_state=12345, max_depth = depth)\n",
    "    train_forest_unbalanced = model_forest_unbalanced.fit(features_train, target_train)\n",
    "    predicition_forest_unbalanced = model_forest_unbalanced.predict(features_valid)\n",
    "    results_forest_unbalanced = f1_score(target_valid,predicition_forest_unbalanced)\n",
    "    if results_forest_unbalanced > best_result_forest_unbalanced:\n",
    "        best_model_forest_unbalanced = model_forest_unbalanced\n",
    "        best_result_forest_unbalanced = results_forest_unbalanced\n",
    "        best_depth_forest_unbalanced = depth\n",
    "\n",
    "print(\"El Valor de f1 del mejor modelo sin balance en el conjunto de validacion es de:\", best_result_forest_unbalanced)\n",
    "print(\"Resultado alcanzado con una profundidad de\", best_depth_forest_unbalanced)\n",
    "\n",
    "probabilities_valid_forest_unbalanced = model_forest_unbalanced.predict_proba(features_valid)\n",
    "probabilities_one_valid_forest_unbalanced = probabilities_valid_forest_unbalanced[:, 1]\n",
    "auc_roc_forest_unbalanced = roc_auc_score(target_valid, probabilities_one_valid_forest_unbalanced)\n",
    "\n",
    "print(f'El valor de AUC-ROC es de: {auc_roc_forest_unbalanced}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresión Logística\n",
    "Se elabora un modelo de regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score del modelo de regresión logística en el conjunto de entrenamiento: 0.25034965034965034\n",
      "F1-score del modelo de regresión logística en el conjunto de validación: 0.21350762527233114\n",
      "El valor de AUC-ROC es de: 0.7300945961119691\n"
     ]
    }
   ],
   "source": [
    "model_regression_unbalanced = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "train_regresson_unbalanced = model_regression_unbalanced.fit(features_train, target_train)\n",
    "\n",
    "predictions_train_unbalanced = model_regression_unbalanced.predict(features_train)\n",
    "predictions_valid_unbalanced = model_regression_unbalanced.predict(features_valid)\n",
    "\n",
    "f1_train_unbalanced = f1_score(target_train, predictions_train_unbalanced)\n",
    "f1_valid_unbalanced = f1_score(target_valid, predictions_valid_unbalanced)\n",
    "\n",
    "print(\"F1-score del modelo de regresión logística en el conjunto de entrenamiento:\", f1_train_unbalanced)\n",
    "print(\"F1-score del modelo de regresión logística en el conjunto de validación:\", f1_valid_unbalanced)\n",
    "\n",
    "probabilities_valid_regression_unbalanced = model_regression_unbalanced.predict_proba(features_valid)\n",
    "probabilities_one_valid_regression_unbalanced = probabilities_valid_regression_unbalanced[:, 1]\n",
    "auc_roc_regression_unbalanced = roc_auc_score(target_valid, probabilities_one_valid_regression_unbalanced)\n",
    "print(f'El valor de AUC-ROC es de: {auc_roc_regression_unbalanced}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observaciones de los modelos no equilibrados\n",
    "\n",
    "Después de haber implementado 3 modelos diferentes, obtuvimos los siguientes resultados:\n",
    "\n",
    "    - Árbol de decisión\n",
    "        El Valor de f1 del mejor modelo sin balance en el conjunto de validacion es de: 0.5514\n",
    "        El valor de AUC-ROC es de: 0.835\n",
    "        \n",
    "    - Bosque aleatorio\n",
    "        El Valor de f1 del mejor modelo sin balance en el conjunto de validacion es de: 0.55\n",
    "        El valor de AUC-ROC es de: 0.8664\n",
    "        \n",
    "    - Regresión logística\n",
    "        F1-score del modelo de regresión logística en el conjunto de validación: 0.2135\n",
    "        El valor de AUC-ROC es de: 0.73\n",
    "    \n",
    "    \n",
    "Para el presente estudio, se solicitaba un umbral de valor F1 de al menos 0.59, por lo tanto los 3 modelos no equilibrados, no pasarían la solicitud. \n",
    "\n",
    "De estos datos podemos indicar:\n",
    "\n",
    "    - Ambos modelos (Árbol de Decisión y Bosque Aleatorio) muestran un F1-score relativamente más alto en comparación con la Regresión Logística en el conjunto de validación. \n",
    "    - El valor de AUC-ROC es alto para ambos modelos, lo cual indica que son capaces de discriminar bien entre las clases positivas y negativas, lo que es mayor que solo adivinar al azar, pero al comparar estos dos valores, nos indica que el modelo puede no ser confiable.\n",
    "\n",
    "    - Para la Regresión Logística el valor F1-score es más bajo (0.2135) en comparación con los modelos basados en árboles.\n",
    "    - El valor de AUC-ROC es aceptable (0.73), pero inferior al de los modelos basados en árboles, lo que igualmente que en el caso anterior, temer un valor \"aceptable\" y el otro por debajo, podría indicar que no hay congruecia y nuestro modelo no es confiable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba de calidad de los modelos\n",
    "\n",
    "Se medirá la calidad de los modelos con el fin de tener datos comparativos cuando el modelo esté equilibrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 del modelo de Árbol de Decisión en el conjunto de prueba: 0.5316455696202532\n",
      "\n",
      "F1 del modelo del bosque aleatorio en el conjunto de prueba: 0.5471698113207547\n",
      "\n",
      "F1 del modelo del regresión logística en el conjunto de prueba: 0.24657534246575344\n"
     ]
    }
   ],
   "source": [
    "predictions_tree_test_unbalanced = model_tree_unbalanced.predict(features_test)\n",
    "result_tree_test_unbalanced = f1_score(target_test, predictions_tree_test_unbalanced)\n",
    "\n",
    "print(\"F1 del modelo de Árbol de Decisión en el conjunto de prueba:\", result_tree_test_unbalanced)\n",
    "print()\n",
    "\n",
    "predictions_forest_test_unbalanced = model_forest_unbalanced.predict(features_test)\n",
    "result_forest_test_unbalanced = f1_score(target_test,predictions_forest_test_unbalanced)\n",
    "\n",
    "print(\"F1 del modelo del bosque aleatorio en el conjunto de prueba:\", result_forest_test_unbalanced)\n",
    "print()\n",
    "\n",
    "predictions_regression_test_unbalanced = model_regression_unbalanced.predict(features_test)\n",
    "result_regression_test_unbalanced = f1_score(target_test, predictions_regression_test_unbalanced)\n",
    "\n",
    "print(\"F1 del modelo del regresión logística en el conjunto de prueba:\", result_regression_test_unbalanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observaciones de los resultados de los test\n",
    "\n",
    "Al correr los modelos usando el conjunto de prueba previamente considerado Se obtuvieron los siguientes datos:\n",
    "\n",
    "    - F1 del modelo de Árbol de Decisión en el conjunto de prueba: 0.5316\n",
    "    - F1 del modelo del bosque aleatorio en el conjunto de prueba: 0.5472\n",
    "    - F1 del modelo del regresión logística en el conjunto de prueba:  0.2465\n",
    "\n",
    "Los modelos de arboles, han bajado algunas centécimas contra el conjunto de validación. Por los valores de F1 se puede indicar que el modelo no está teniendo un buen desempeño en términos de precisión y recall. Por lo que puede estar clasificando incorrectamente muchos casos positivos o negativos.\n",
    "\n",
    "Con estos datos podemos terminar de concluir que el desequilibrio de clase, nos da resultados apenas aceptables para los árboles de decisión y bosque aleatorio y muy bajo para F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejora de la calidad del modelo\n",
    "\n",
    "Viendo que los resultados obtenidos por modelos con clases desequilibradas no fueron satisfactios, se procede a mejorar la calidad del modelo corrigiendo el desequilibrio de clases.\n",
    "\n",
    "Se equilibrará las clases por medio de las siguientes estrategias:\n",
    "\n",
    "    - Ajuste de pesos de clase\n",
    "    - Sobremuestreo de la clase minoritaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste de pesos de clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelos balanceados\n",
    "\n",
    "Se realizarán los modelos:\n",
    "\n",
    "    - Árboles de decisión\n",
    "    - Bosque Aleatorio\n",
    "    - Módelo de regresión logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Valor de f1 del mejor modelo balanceado en el conjunto de validacion es de: 0.5758928571428572\n",
      "Resultado alcanzado con una profundidad de 5\n",
      "El valor de AUC-ROC es de: 0.8305203614495533\n"
     ]
    }
   ],
   "source": [
    "best_model_tree = None\n",
    "best_result_tree = 0\n",
    "best_depth_tree = 0\n",
    "\n",
    "\n",
    "for depth_tree in range(1, 6):\n",
    "    model_tree = DecisionTreeClassifier(random_state=12345, max_depth=depth_tree, class_weight='balanced')\n",
    "    model_tree.fit(features_train, target_train)\n",
    "    predicted_valid_tree = model_tree.predict(features_valid)\n",
    "    result_tree = f1_score(target_valid, predicted_valid_tree)\n",
    "    \n",
    "    if result_tree > best_result_tree:\n",
    "        best_model_tree = model_tree\n",
    "        best_result_tree = result_tree\n",
    "        best_depth_tree = depth_tree\n",
    "\n",
    "print(\"El Valor de f1 del mejor modelo balanceado en el conjunto de validacion es de:\", best_result_tree)\n",
    "print(\"Resultado alcanzado con una profundidad de\", best_depth_tree)\n",
    "\n",
    "probabilities_valid_tree = model_tree.predict_proba(features_valid)\n",
    "probabilities_one_valid_tree = probabilities_valid_tree[:, 1]\n",
    "auc_roc_tree = roc_auc_score(target_valid, probabilities_one_valid_tree)\n",
    "\n",
    "print(f'El valor de AUC-ROC es de: {auc_roc_tree}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bosque Aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Valor de f1 del mejor modelo balancado en el conjunto de validacion es de: 0.6355828220858895\n",
      "Resultado alcanzado con una profundidad de 9\n",
      "El valor de AUC-ROC es de: 0.8648669046142066\n"
     ]
    }
   ],
   "source": [
    "best_model_forest= None\n",
    "best_result_forest= 0\n",
    "best_depth_forest = 0\n",
    "\n",
    "for depth_forest in range(1,10):\n",
    "    model_forest = RandomForestClassifier(random_state=12345, max_depth = depth_forest, class_weight='balanced')\n",
    "    train_forest = model_forest.fit(features_train, target_train)\n",
    "    predicition_forest = model_forest.predict(features_valid)\n",
    "    results_forest = f1_score(target_valid, predicition_forest)\n",
    "    \n",
    "    if results_forest > best_result_forest:\n",
    "        best_model_forest = model_forest\n",
    "        best_result_forest = results_forest\n",
    "        best_depth_forest = depth_forest\n",
    "\n",
    "print(\"El Valor de f1 del mejor modelo balancado en el conjunto de validacion es de:\", best_result_forest)\n",
    "print(\"Resultado alcanzado con una profundidad de\", best_depth_forest)\n",
    "\n",
    "probabilities_valid_forest = model_forest.predict_proba(features_valid)\n",
    "probabilities_one_valid_forest = probabilities_valid_forest[:, 1]\n",
    "auc_roc_forest = roc_auc_score(target_valid, probabilities_one_valid_forest)\n",
    "\n",
    "print(f'El valor de AUC-ROC es de: {auc_roc_forest}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Módelo regresión logísitca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score del modelo de regresión logística en el conjunto de entrenamiento: 0.48314960629921255\n",
      "F1-score del modelo de regresión logística en el conjunto de validación: 0.4797794117647059\n",
      "El valor de AUC-ROC es de: 0.757002670927388\n"
     ]
    }
   ],
   "source": [
    "model_regression = LogisticRegression(random_state=12345, class_weight='balanced', solver='liblinear')\n",
    "train_regresson = model_regression.fit(features_train, target_train)\n",
    "\n",
    "predictions_train = model_regression.predict(features_train)\n",
    "predictions_valid = model_regression.predict(features_valid)\n",
    "\n",
    "f1_train = f1_score(target_train, predictions_train)\n",
    "f1_valid = f1_score(target_valid, predictions_valid)\n",
    "\n",
    "print(\"F1-score del modelo de regresión logística en el conjunto de entrenamiento:\", f1_train)\n",
    "print(\"F1-score del modelo de regresión logística en el conjunto de validación:\", f1_valid)\n",
    "\n",
    "probabilities_valid_regression = model_regression.predict_proba(features_valid)\n",
    "probabilities_one_valid_regression = probabilities_valid_regression[:, 1]\n",
    "auc_roc_regression = roc_auc_score(target_valid, probabilities_one_valid_regression)\n",
    "print(f'El valor de AUC-ROC es de: {auc_roc_regression}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prueba de calidad de los modelos equilibrados\n",
    "\n",
    "Se realizará la pruebad de calidad de los modelos equilibrados con los datos test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 del modelo de Árbol de Decisión en el conjunto de prueba: 0.5488810365135454\n",
      "\n",
      "F1 del modelo del bosque aleatorio en el conjunto de prueba: 0.5846560846560848\n",
      "\n",
      "F1 del modelo del regresión logística en el conjunto de prueba: 0.476\n"
     ]
    }
   ],
   "source": [
    "predictions_tree_test = model_tree.predict(features_test)\n",
    "result_tree_test = f1_score(target_test, predictions_tree_test)\n",
    "\n",
    "print(\"F1 del modelo de Árbol de Decisión en el conjunto de prueba:\", result_tree_test)\n",
    "print()\n",
    "\n",
    "predictions_forest_test = model_forest.predict(features_test)\n",
    "result_forest_test = f1_score(target_test, predictions_forest_test)\n",
    " \n",
    "print(\"F1 del modelo del bosque aleatorio en el conjunto de prueba:\", result_forest_test)\n",
    "print()\n",
    "\n",
    "predictions_regression_test = model_regression.predict(features_test)\n",
    "result_regression_test = f1_score(target_test, predictions_regression_test)\n",
    "\n",
    "print(\"F1 del modelo del regresión logística en el conjunto de prueba:\", result_regression_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Revisión de los datos\n",
    "\n",
    "A continuación, se muestra una tabla comparativa de los datos de cada uno de los modelos, una columna muestra los datos desequilibrados y los datos ya equilibrados:\n",
    "\n",
    "Resultados de Árbol de desición | Desequilibrado | Equilibrado\n",
    "--- | --- | ---\n",
    "El Valor de f1 del mejor modelo en el conjunto de validacion | 55.14% | 57.59%\n",
    "Mejor resultado alcanzado con una profundidad | 5 | 5\n",
    "El valor de AUC-ROC | 83.50% | 83.05%\n",
    "F1 del modelo de Árbol de Decisión en el conjunto de prueba | 53.50% | 54.89%\n",
    "\n",
    "\n",
    "Resultados de Bosque aleatorio | Desequilibrado | Equilibrado\n",
    "--- | --- | ---\n",
    "El Valor de f1 del mejor modelo en el conjunto de validacion | 55% | 63.56%\n",
    "Mejor resultado alcanzado con una profundidad | 6 | 9\n",
    "El valor de AUC-ROC | 86.64% | 86.49%\n",
    "F1 del modelo del bosque aleatorio en el conjunto de prueba | 54.72% | 58.46%\n",
    "\n",
    "\n",
    "Resultados de regesión | Desequilibrado | Equilibrado\n",
    "--- | --- | ---\n",
    "F1-score del modelo de regresión logística en el conjunto de entrenamiento | 25.03% | 48.31%\n",
    "F1-score del modelo de regresión logística en el conjunto de validación | 21.35% | 47.98%\n",
    "El valor de AUC-ROC | 73.01% | 75.70%\n",
    "F1 del modelo del regresión logística en el conjunto de prueba | 24.66% | 47.60%\n",
    "\n",
    "\n",
    "Se observa que en general y en la mayoria de los casos, los porcentajes de los modelos equilibrados dan porcentajes más altos, siendo el bosque aleatorio de profundidad 9, el que más se acerca al 59% deseado en F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobremuestreo de la clase minoritaria\n",
    "\n",
    "Ahora se balanceará los datos por medio de el sobremuestreo de la clase minoritaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Función de sobremuestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345\n",
    "    )\n",
    "\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(\n",
    "    features_train, target_train, 7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utilizarán los 3 modelos con el sobremuestreo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Valor de f1 del mejor modelo balanceado en el conjunto de validacion es de: 0.5487179487179487\n",
      "Resultado alcanzado con una profundidad de 5\n",
      "AUC-ROC: 0.8455068227376731\n"
     ]
    }
   ],
   "source": [
    "best_model_tree_upsampled = None\n",
    "best_result_tree_upsampled = 0\n",
    "best_depth_tree_upsampled = 0\n",
    "\n",
    "\n",
    "for depth_tree_upsampled in range(1, 6):\n",
    "    model_tree_upsampled = DecisionTreeClassifier(random_state=12345, max_depth=depth_tree_upsampled)\n",
    "    model_tree_upsampled.fit(features_upsampled, target_upsampled)\n",
    "    predicted_valid_upsampled_tree = model_tree_upsampled.predict(features_valid)\n",
    "    result_tree_upsampled = f1_score(target_valid, predicted_valid_upsampled_tree)\n",
    "    \n",
    "    if result_tree_upsampled > best_result_tree_upsampled:\n",
    "        best_model_tree_upsampled = model_tree_upsampled\n",
    "        best_result_tree_upsampled = result_tree_upsampled\n",
    "        best_depth_tree_upsampled = depth_tree_upsampled\n",
    "\n",
    "print(\"El Valor de f1 del mejor modelo balanceado en el conjunto de validacion es de:\", best_result_tree_upsampled)\n",
    "print(\"Resultado alcanzado con una profundidad de\", best_depth_tree_upsampled)\n",
    "\n",
    "probabilities_valid_tree_upsampled = best_model_tree_upsampled.predict_proba(features_valid)\n",
    "probabilities_one_valid_tree_upsampled = probabilities_valid_tree_upsampled[:, 1]\n",
    "auc_roc_tree_upsampled = roc_auc_score(target_valid, probabilities_one_valid_tree_upsampled)\n",
    "\n",
    "print(f'AUC-ROC: {auc_roc_tree_upsampled}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bosque Aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Valor de f1 del mejor modelo balancado en el conjunto de validacion es de: 0.5666957279860506\n",
      "Resultado alcanzado con una profundidad de 8\n",
      "AUC-ROC: 0.8606534292241056\n"
     ]
    }
   ],
   "source": [
    "best_model_forest_upsampled = None\n",
    "best_result_forest_upsampled = 0\n",
    "best_depth_forest_upsampled = 0\n",
    "\n",
    "for depth_forest_upsampled in range(1,10):\n",
    "    model_forest_upsampled = RandomForestClassifier(random_state=12345, max_depth = depth_forest_upsampled,)\n",
    "    model_forest_upsampled.fit(features_upsampled, target_upsampled)\n",
    "    predicted_valid_upsampled_forest = model_forest_upsampled.predict(features_valid)\n",
    "    results_forest_upsampled = f1_score(target_valid, predicted_valid_upsampled_forest)\n",
    "    \n",
    "    if results_forest_upsampled > best_result_forest_upsampled:\n",
    "        best_model_forest_upsampled = model_forest_upsampled\n",
    "        best_result_forest_upsampled = results_forest_upsampled\n",
    "        best_depth_forest_upsampled = depth_forest_upsampled\n",
    "\n",
    "print(\"El Valor de f1 del mejor modelo balancado en el conjunto de validacion es de:\", best_result_forest_upsampled)\n",
    "print(\"Resultado alcanzado con una profundidad de\", best_depth_forest_upsampled)\n",
    "\n",
    "probabilities_valid_forest_upsampled = best_model_forest_upsampled.predict_proba(features_valid)\n",
    "probabilities_one_valid_forest_upsampled = probabilities_valid_forest_upsampled[:, 1]\n",
    "auc_roc_forest_upsampled = roc_auc_score(target_valid, probabilities_one_valid_forest_upsampled)\n",
    "\n",
    "print(f'AUC-ROC: {auc_roc_forest_upsampled}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Módelo regresión logísitca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score del modelo de regresión logística en el conjunto de entrenamiento: 0.43166740380362667\n",
      "F1-score del modelo de regresión logística en el conjunto de validación: 0.4422310756972111\n",
      "AUC-ROC: 0.7575714624938105\n"
     ]
    }
   ],
   "source": [
    "model_regression_upsampled = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model_regression_upsampled.fit(features_upsampled, target_upsampled)\n",
    "\n",
    "predictions_train_upsampled_regression = model_regression_upsampled.predict(features_train)\n",
    "predictions_valid_upsampled_regression = model_regression_upsampled.predict(features_valid)\n",
    "                                  \n",
    "f1_train_upsampled = f1_score(target_train, predictions_train_upsampled_regression)\n",
    "f1_valid_upsampled = f1_score(target_valid, predictions_valid_upsampled_regression)                                   \n",
    "\n",
    "print(\"F1-score del modelo de regresión logística en el conjunto de entrenamiento:\", f1_train_upsampled)\n",
    "print(\"F1-score del modelo de regresión logística en el conjunto de validación:\", f1_valid_upsampled)\n",
    "\n",
    "probabilities_valid_regression_upsampled = model_regression_upsampled.predict_proba(features_valid)\n",
    "probabilities_one_valid_regression_upsampled = probabilities_valid_regression_upsampled[:, 1]\n",
    "auc_roc_regression_upsampled = roc_auc_score(target_valid, probabilities_one_valid_regression_upsampled)\n",
    "\n",
    "print(f'AUC-ROC: {auc_roc_regression_upsampled}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prueba de calidad de los modelos equilibrados\n",
    "Se realizará la prueba de calidad de los modelos equilibrados con los datos test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 del modelo de Árbol de Decisión en el conjunto de prueba: 0.5185185185185185\n",
      "\n",
      "F1 del modelo del bosque aleatorio en el conjunto de prueba: 0.5332120109190173\n",
      "\n",
      "F1 del modelo del regresión logística en el conjunto de prueba: 0.42937062937062936\n"
     ]
    }
   ],
   "source": [
    "predictions_tree_test_upsampled = best_model_tree_upsampled.predict(features_test)\n",
    "result_tree_test_upsampled = f1_score(target_test, predictions_tree_test_upsampled)\n",
    "\n",
    "print(\"F1 del modelo de Árbol de Decisión en el conjunto de prueba:\", result_tree_test_upsampled)\n",
    "print()\n",
    "\n",
    "predictions_forest_test_upsampled = best_model_forest_upsampled.predict(features_test)\n",
    "result_forest_test_upsampled = f1_score(target_test, predictions_forest_test_upsampled)\n",
    " \n",
    "print(\"F1 del modelo del bosque aleatorio en el conjunto de prueba:\", result_forest_test_upsampled)\n",
    "print()\n",
    "\n",
    "predictions_regression_test_upsampled = model_regression_upsampled.predict(features_test)\n",
    "result_regression_test_upsampled = f1_score(target_test, predictions_regression_test_upsampled)\n",
    "\n",
    "print(\"F1 del modelo del regresión logística en el conjunto de prueba:\", result_regression_test_upsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Revisión de los datos\n",
    "\n",
    "A continuación, se muestra una tabla comparativa de los datos de cada uno de los modelos realizados con sobremuestreo. En una columna se muestran los datos desequilibrados y en la otra columna los datos ya equilibrados:\n",
    "\n",
    "Resultados de Árbol de desición | Desequilibrado | Equilibrado\n",
    "--- | --- | ---\n",
    "El Valor de f1 del mejor modelo en el conjunto de validacion | 55.14% | 54.87%\n",
    "Mejor resultado alcanzado con una profundidad | 5 | 5\n",
    "El valor de AUC-ROC | 83.50% | 84.55%\n",
    "F1 del modelo de Árbol de Decisión en el conjunto de prueba | 53.16% | 51.85%\n",
    "\n",
    "\n",
    "Resultados de Bosque aleatorio | Desequilibrado | Equilibrado\n",
    "--- | --- | ---\n",
    "El Valor de f1 del mejor modelo en el conjunto de validacion | 55% | 56.67%\n",
    "Mejor resultado alcanzado con una profundidad | 6 | 8\n",
    "El valor de AUC-ROC | 86.64% | 86.07%\n",
    "F1 del modelo del bosque aleatorio en el conjunto de prueba | 54.72% | 53.32%\n",
    "\n",
    "\n",
    "Resultados de regesión | Desequilibrado | Equilibrado\n",
    "--- | --- | ---\n",
    "F1-score del modelo de regresión logística en el conjunto de entrenamiento | 25.03% | 43.17%\n",
    "F1-score del modelo de regresión logística en el conjunto de validación | 21.35% | 42.22%\n",
    "El valor de AUC-ROC | 73.01% | 75.76%\n",
    "F1 del modelo del regresión logística en el conjunto de prueba | 24.66% | 42.94%\n",
    "\n",
    "\n",
    "Se observa que en general y en la mayoria de los casos, los porcentajes de los modelos equilibrados dan porcentajes más altos, sin embargo no se llega a obtener el valor de F1 buscado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despues de realizar el equilibrio de modelos utilizando Ajuste de pesos de clase y sobremuestreo y no haber llegado al F1 solicitado, se realizará un submuestreo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submuestreo\n",
    "\n",
    "Después de realizar el equilibrio de clases en diferentes modelos y correrlos, se encuentra la mejor opción que nos da los resultados buscados.\n",
    "\n",
    "Se elige el modelo de Bosque Aleatorio, con un equilibrio de clases con sobremuestreo con repetición de 8.\n",
    "\n",
    "Se realiza la prueba final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Función de submuestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)]\n",
    "        + [features_ones]\n",
    "    )\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)]\n",
    "        + [target_ones]\n",
    "    )\n",
    "\n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345\n",
    "    )\n",
    "\n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "\n",
    "features_downsampled, target_downsampled = downsample(\n",
    "    features_train, target_train, 0.35\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utilizarán los 3 modelos con el sobremuestreo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Valor de f1 del mejor modelo balanceado en el conjunto de validacion es de: 0.5743473325766175\n",
      "Resultado alcanzado con una profundidad de 5\n",
      "AUC-ROC: 0.8304522537215351\n"
     ]
    }
   ],
   "source": [
    "best_model_tree_downsample = None\n",
    "best_result_tree_downsample = 0\n",
    "best_depth_tree_downsample = 0\n",
    "\n",
    "\n",
    "for depth_tree_downsample in range(1, 6):\n",
    "    model_tree_downsample = DecisionTreeClassifier(random_state=12345, max_depth=depth_tree_downsample)\n",
    "    model_tree_downsample.fit(features_downsampled, target_downsampled)\n",
    "    predicted_valid_downsample_tree = model_tree_downsample.predict(features_valid)\n",
    "    result_tree_downsample = f1_score(target_valid, predicted_valid_downsample_tree)\n",
    "    \n",
    "    if result_tree_downsample > best_result_tree_downsample:\n",
    "        best_model_tree_downsample = model_tree_downsample\n",
    "        best_result_tree_downsample = result_tree_downsample\n",
    "        best_depth_tree_downsample = depth_tree_downsample\n",
    "\n",
    "print(\"El Valor de f1 del mejor modelo balanceado en el conjunto de validacion es de:\", best_result_tree_downsample)\n",
    "print(\"Resultado alcanzado con una profundidad de\", best_depth_tree_downsample)\n",
    "\n",
    "probabilities_valid_tree_downsample = best_model_tree_downsample.predict_proba(features_valid)\n",
    "probabilities_one_valid_tree_downsample = probabilities_valid_tree_downsample[:, 1]\n",
    "auc_roc_tree_downsample = roc_auc_score(target_valid, probabilities_one_valid_tree_downsample)\n",
    "\n",
    "print(f'AUC-ROC: {auc_roc_tree_downsample}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bosque Aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Valor de f1 del mejor modelo balancado en el conjunto de validacion es de: 0.6169965075669382\n",
      "Resultado alcanzado con una profundidad de 6\n",
      "AUC-ROC: 0.8626083050931695\n"
     ]
    }
   ],
   "source": [
    "best_model_forest_downsample = None\n",
    "best_result_forest_downsample = 0\n",
    "best_depth_forest_downsample = 0\n",
    "\n",
    "for depth_forest_downsample in range(1,10):\n",
    "    model_forest_downsample = RandomForestClassifier(random_state=12345, max_depth = depth_forest_downsample)\n",
    "    model_forest_downsample.fit(features_downsampled, target_downsampled)\n",
    "    predicted_valid_downsample_forest = model_forest_downsample.predict(features_valid)\n",
    "    results_forest_downsample = f1_score(target_valid, predicted_valid_downsample_forest)\n",
    "    \n",
    "    if results_forest_downsample > best_result_forest_downsample:\n",
    "        best_model_forest_downsample = model_forest_downsample\n",
    "        best_result_forest_downsample = results_forest_downsample\n",
    "        best_depth_forest_downsample = depth_forest_downsample\n",
    "\n",
    "print(\"El Valor de f1 del mejor modelo balancado en el conjunto de validacion es de:\", best_result_forest_downsample)\n",
    "print(\"Resultado alcanzado con una profundidad de\", best_depth_forest_downsample)\n",
    "\n",
    "probabilities_valid_forest_downsample = best_model_forest_downsample.predict_proba(features_valid)\n",
    "probabilities_one_valid_forest_downsample = probabilities_valid_forest_downsample[:, 1]\n",
    "auc_roc_forest_downsample = roc_auc_score(target_valid, probabilities_one_valid_forest_downsample)\n",
    "\n",
    "print(f'AUC-ROC: {auc_roc_forest_downsample}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score del modelo de regresión logística en el conjunto de entrenamiento: 0.4669316949765089\n",
      "F1-score del modelo de regresión logística en el conjunto de validación: 0.47108307045215564\n",
      "AUC-ROC: 0.742346624157627\n"
     ]
    }
   ],
   "source": [
    "model_regression_downsample = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model_regression_downsample.fit(features_downsampled, target_downsampled)\n",
    "\n",
    "predictions_train_downsample_regression = model_regression_downsample.predict(features_train)\n",
    "predictions_valid_downsample_regression = model_regression_downsample.predict(features_valid)\n",
    "                                  \n",
    "f1_train_downsample = f1_score(target_train, predictions_train_downsample_regression)\n",
    "f1_valid_downsample = f1_score(target_valid, predictions_valid_downsample_regression)                                   \n",
    "\n",
    "print(\"F1-score del modelo de regresión logística en el conjunto de entrenamiento:\", f1_train_downsample)\n",
    "print(\"F1-score del modelo de regresión logística en el conjunto de validación:\", f1_valid_downsample)\n",
    "\n",
    "probabilities_valid_regression_downsample = model_regression_downsample.predict_proba(features_valid)\n",
    "probabilities_one_valid_regression_downsample = probabilities_valid_regression_downsample[:, 1]\n",
    "auc_roc_regression_downsample = roc_auc_score(target_valid, probabilities_one_valid_regression_downsample)\n",
    "\n",
    "print(f'AUC-ROC: {auc_roc_regression_downsample}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prueba de calidad de los modelos equilibrados\n",
    "\n",
    "Se realizará la prueba de calidad de los modelos equilibrados con los datos test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 del modelo de Árbol de Decisión en el conjunto de prueba: 0.5563725490196079\n",
      "\n",
      "F1 del modelo del bosque aleatorio en el conjunto de prueba: 0.5960591133004928\n",
      "\n",
      "F1 del modelo del regresión logística en el conjunto de prueba: 0.4680365296803653\n"
     ]
    }
   ],
   "source": [
    "predictions_tree_test_downsample = model_tree_downsample.predict(features_test)\n",
    "result_tree_test_downsample = f1_score(target_test, predictions_tree_test_downsample)\n",
    "\n",
    "print(\"F1 del modelo de Árbol de Decisión en el conjunto de prueba:\", result_tree_test_downsample)\n",
    "print()\n",
    "\n",
    "predictions_forest_test_downsample = model_forest_downsample.predict(features_test)\n",
    "result_forest_test_downsample = f1_score(target_test, predictions_forest_test_downsample)\n",
    "\n",
    "print(\"F1 del modelo del bosque aleatorio en el conjunto de prueba:\", result_forest_test_downsample)\n",
    "print()\n",
    "\n",
    "predictions_regression_test_downsample = model_regression_downsample.predict(features_test)\n",
    "result_regression_test_downsample = f1_score(target_test, predictions_regression_test_downsample)\n",
    "\n",
    "print(\"F1 del modelo del regresión logística en el conjunto de prueba:\", result_regression_test_downsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Revisión de los datos\n",
    "\n",
    "A continuación, se muestra una tabla comparativa de los datos de cada uno de los modelos realizados con sobremuestreo. En una columna se muestran los datos desequilibrados y en la otra columna los datos ya equilibrados:\n",
    "\n",
    "Resultados de Árbol de desición | Desequilibrado | Equilibrado\n",
    "--- | --- | ---\n",
    "El Valor de f1 del mejor modelo en el conjunto de validacion | 55.14% | 57.43%\n",
    "Mejor resultado alcanzado con una profundidad | 5 | 5\n",
    "El valor de AUC-ROC | 83.50% | 83.05%\n",
    "F1 del modelo de Árbol de Decisión en el conjunto de prueba | 53.16% | 55.64%\n",
    "\n",
    "\n",
    "Resultados de Bosque aleatorio | Desequilibrado | Equilibrado\n",
    "--- | --- | ---\n",
    "El Valor de f1 del mejor modelo en el conjunto de validacion | 55% | 61.7%\n",
    "Mejor resultado alcanzado con una profundidad | 6 | 6\n",
    "El valor de AUC-ROC | 86.64% | 86.26%\n",
    "F1 del modelo del bosque aleatorio en el conjunto de prueba | 54.72% | 59.61%\n",
    "\n",
    "\n",
    "Resultados de regesión | Desequilibrado | Equilibrado\n",
    "--- | --- | ---\n",
    "F1-score del modelo de regresión logística en el conjunto de entrenamiento | 25.03% | 46.69%\n",
    "F1-score del modelo de regresión logística en el conjunto de validación | 21.35% | 47.11%\n",
    "El valor de AUC-ROC | 73.01% | 74.23%\n",
    "F1 del modelo del regresión logística en el conjunto de prueba | 24.66% | 46.80%\n",
    "\n",
    "\n",
    "Ahora hemos podido encontrar un F1 que con los datos de prueba sea como mínimo 59%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparativo Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Revisión de los datos\n",
    "\n",
    "A continuación, se muestra una tabla comparativa de los datos de cada uno de los modelos realizados con sobremuestreo. En una columna se muestran los datos desequilibrados y en la otra columna los datos ya equilibrados:\n",
    "\n",
    "Resultados de Árbol de desición | Desequilibrado | Ajuste de pesos | Sobremuestreo | Submuestreo\n",
    "--- | --- | --- | --- | ---\n",
    "El Valor de f1 del mejor modelo en el conjunto de validacion | 55.14% | 57.59% | 54.87% | 57.43%\n",
    "Mejor resultado alcanzado con una profundidad | 5 | 5 | 5 | 5\n",
    "El valor de AUC-ROC | 83.50% | 83.05% | 84.55% | 83.05%\n",
    "F1 del modelo de Árbol de Decisión en el conjunto de prueba | 53.50% | 54.89% | 51.85% | 55.64%\n",
    "\n",
    "\n",
    "Resultados de Bosque aleatorio | Desequilibrado | Ajuste de pesos | Sobremuestreo | Submuestreo\n",
    "--- | --- | --- | --- | ---\n",
    "El Valor de f1 del mejor modelo en el conjunto de validacion | 55% | 63.56% | 56.67% | 61.70%\n",
    "Mejor resultado alcanzado con una profundidad | 6 | 9 | 8 | 6\n",
    "El valor de AUC-ROC | 86.64% | 86.49% | 86.07% | 86.26%\n",
    "F1 del modelo del bosque aleatorio en el conjunto de prueba | 54.72% | <span style=\"color:brown;font-weight:bold;\">58.46%</span> | 53.32% | <span style=\"color:green;font-weight:bold;\">59.61%</span>\n",
    "\n",
    "\n",
    "Resultados de regesión | Desequilibrado | Ajuste de pesos | Sobremuestreo | Submuestreo\n",
    "--- | --- | --- | --- | ---\n",
    "F1-score del modelo de regresión logística en el conjunto de entrenamiento | 25.03% | 48.31% | 43.17% | 46.69%\n",
    "F1-score del modelo de regresión logística en el conjunto de validación | 21.35% | 47.98% | 44.22% | 47.11%\n",
    "El valor de AUC-ROC | 73.01% | 75.70% | 75.76% | 74.23%\n",
    "F1 del modelo del regresión logística en el conjunto de prueba | 24.66% | 47.60% | 42.94% | 46.80%\n",
    "\n",
    "\n",
    "Ahora hemos podido encontrar un F1 que con los datos de prueba sea como mínimo 59%\n",
    "\n",
    "Con el ajuste de pesos de clase para el modelo de Bosque aleatorio obtuvo un resultado muy cercano al del F1 deseado, con un valor del 58.46%.\n",
    "El modelo de bosque aleatorio con equilibrio de clase de submuestreo fue el que finalmente nos proporcionó un valor de f1 del 59.61%, teniendo el mínimo de buscado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "264.1px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
